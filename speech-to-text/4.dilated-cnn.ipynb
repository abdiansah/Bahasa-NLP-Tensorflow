{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['CUDA_VISIBLE_DEVICES'] = '2'\n",
    "# I have multi-gpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8184"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spectrogram = glob.glob('spectrogram-train/*npy')\n",
    "len(spectrogram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'tolong sebut pariahship'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def filter_text(string):\n",
    "    string = string.lower()\n",
    "    splitted = string.split('/')[1].split('.')[0].replace('<>','-').split('-')\n",
    "    splitted = [w for w in splitted if not w.isdigit() and w not in ['man', 'woman', 'augment']]\n",
    "    return ' '.join(splitted)\n",
    "\n",
    "filter_text(spectrogram[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X, train_Y = [], []\n",
    "for spec in spectrogram:\n",
    "    train_Y.append(filter_text(spec))\n",
    "    train_X.append(np.load(spec))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "293"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spectrogram = glob.glob('spectrogram-test/*npy')\n",
    "len(spectrogram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_X, test_Y = [], []\n",
    "for spec in spectrogram:\n",
    "    test_Y.append(filter_text(spec))\n",
    "    test_X.append(np.load(spec))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/husein/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/husein/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/husein/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/husein/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/husein/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/husein/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/home/husein/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/husein/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/husein/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/husein/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/husein/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/husein/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X = tf.keras.preprocessing.sequence.pad_sequences(\n",
    "    train_X, dtype = 'float32', padding = 'post'\n",
    ")\n",
    "\n",
    "test_X = tf.keras.preprocessing.sequence.pad_sequences(\n",
    "    test_X, dtype = 'float32', padding = 'post'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "chars = list(set([c for target in train_Y + test_Y for c in target]))\n",
    "num_classes = len(chars) + 2\n",
    "\n",
    "idx2char = {idx + 1: char for idx, char in enumerate(chars)}\n",
    "idx2char[0] = '<PAD>'\n",
    "char2idx = {char: idx for idx, char in idx2char.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_Y = [[char2idx[c] for c in target] for target in train_Y]\n",
    "test_Y = [[char2idx[c] for c in target] for target in test_Y]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_sentence_batch(sentence_batch, pad_int):\n",
    "    padded_seqs = []\n",
    "    seq_lens = []\n",
    "    max_sentence_len = max([len(sentence) for sentence in sentence_batch])\n",
    "    for sentence in sentence_batch:\n",
    "        padded_seqs.append(sentence + [pad_int] * (max_sentence_len - len(sentence)))\n",
    "        seq_lens.append(len(sentence))\n",
    "    return padded_seqs, seq_lens\n",
    "\n",
    "def sparse_tuple_from(sequences, dtype=np.int32):\n",
    "    indices = []\n",
    "    values = []\n",
    "\n",
    "    for n, seq in enumerate(sequences):\n",
    "        indices.extend(zip([n] * len(seq), range(len(seq))))\n",
    "        values.extend(seq)\n",
    "\n",
    "    indices = np.asarray(indices, dtype=np.int64)\n",
    "    values = np.asarray(values, dtype=dtype)\n",
    "    shape = np.asarray([len(sequences), np.asarray(indices).max(0)[1] + 1], dtype=np.int64)\n",
    "\n",
    "    return indices, values, shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_second_dim(x, desired_size):\n",
    "    padding = tf.tile([[0]], tf.stack([tf.shape(x)[0], desired_size - tf.shape(x)[1]], 0))\n",
    "    return tf.concat([x, padding], 1)\n",
    "\n",
    "def position_encoding(inputs):\n",
    "    T = tf.shape(inputs)[1]\n",
    "    repr_dim = inputs.get_shape()[-1].value\n",
    "    pos = tf.reshape(tf.range(0.0, tf.to_float(T), dtype=tf.float32), [-1, 1])\n",
    "    i = np.arange(0, repr_dim, 2, np.float32)\n",
    "    denom = np.reshape(np.power(10000.0, i / repr_dim), [1, -1])\n",
    "    enc = tf.expand_dims(tf.concat([tf.sin(pos / denom), tf.cos(pos / denom)], 1), 0)\n",
    "    return tf.tile(enc, [tf.shape(inputs)[0], 1, 1])\n",
    "\n",
    "def layer_norm(inputs, epsilon=1e-8):\n",
    "    mean, variance = tf.nn.moments(inputs, [-1], keep_dims=True)\n",
    "    normalized = (inputs - mean) / (tf.sqrt(variance + epsilon))\n",
    "    params_shape = inputs.get_shape()[-1:]\n",
    "    gamma = tf.get_variable('gamma', params_shape, tf.float32, tf.ones_initializer())\n",
    "    beta = tf.get_variable('beta', params_shape, tf.float32, tf.zeros_initializer())\n",
    "    return gamma * normalized + beta\n",
    "\n",
    "def cnn_block(x, dilation_rate, pad_sz, hidden_dim, kernel_size):\n",
    "    x = layer_norm(x)\n",
    "    pad = tf.zeros([tf.shape(x)[0], pad_sz, hidden_dim])\n",
    "    x =  tf.layers.conv1d(inputs = tf.concat([pad, x, pad], 1),\n",
    "                          filters = hidden_dim,\n",
    "                          kernel_size = kernel_size,\n",
    "                          dilation_rate = dilation_rate)\n",
    "    x = x[:, :-pad_sz, :]\n",
    "    x = tf.nn.relu(x)\n",
    "    return x\n",
    "\n",
    "class Model:\n",
    "    def __init__(\n",
    "        self,\n",
    "        num_layers,\n",
    "        size_layers,\n",
    "        learning_rate,\n",
    "        num_features,\n",
    "        dropout = 1.0,\n",
    "        kernel_size = 3,\n",
    "        n_attn_heads = 16\n",
    "    ):\n",
    "        self.X = tf.placeholder(tf.float32, [None, None, num_features])\n",
    "        self.Y = tf.sparse_placeholder(tf.int32)\n",
    "        seq_lens = tf.count_nonzero(\n",
    "            tf.reduce_sum(self.X, -1), 1, dtype = tf.int32\n",
    "        ) + 10\n",
    "        filled = tf.fill(tf.shape(seq_lens), tf.shape(self.X)[1])\n",
    "        seq_lens = tf.where(seq_lens > tf.shape(self.X)[1], filled, seq_lens)\n",
    "        self.label = tf.placeholder(tf.int32, [None, None])\n",
    "        self.Y_seq_len = tf.placeholder(tf.int32, [None])\n",
    "        forward = tf.layers.conv1d(self.X, size_layers, \n",
    "                                   kernel_size = 1, strides = 1, padding = 'SAME')\n",
    "        encoder_embedded = tf.identity(forward)\n",
    "        for i in range(num_layers): \n",
    "                    dilation_rate = 2 ** i\n",
    "                    pad_sz = (kernel_size - 1) * dilation_rate \n",
    "                    with tf.variable_scope('block_%d'%i):\n",
    "                        encoder_embedded += cnn_block(encoder_embedded, dilation_rate, \n",
    "                                       pad_sz, size_layers, kernel_size)\n",
    "        \n",
    "        encoder_embedded = tf.nn.sigmoid(encoder_embedded)\n",
    "        logits = tf.layers.dense(encoder_embedded, num_classes)\n",
    "        time_major = tf.transpose(logits, [1, 0, 2])\n",
    "        decoded, log_prob = tf.nn.ctc_beam_search_decoder(time_major, seq_lens)\n",
    "        decoded = tf.to_int32(decoded[0])\n",
    "        self.preds = tf.sparse_tensor_to_dense(decoded)\n",
    "        self.cost = tf.reduce_mean(\n",
    "            tf.nn.ctc_loss(\n",
    "                self.Y,\n",
    "                time_major,\n",
    "                seq_lens\n",
    "            )\n",
    "        )\n",
    "        self.optimizer = tf.train.AdamOptimizer(\n",
    "            learning_rate = learning_rate\n",
    "        ).minimize(self.cost)\n",
    "        \n",
    "        preds = self.preds[:, :tf.reduce_max(self.Y_seq_len)]\n",
    "        masks = tf.sequence_mask(self.Y_seq_len, tf.reduce_max(self.Y_seq_len), dtype=tf.float32)\n",
    "        preds = pad_second_dim(preds, tf.reduce_max(self.Y_seq_len))\n",
    "        y_t = tf.cast(preds, tf.int32)\n",
    "        self.prediction = tf.boolean_mask(y_t, masks)\n",
    "        mask_label = tf.boolean_mask(self.label, masks)\n",
    "        self.mask_label = mask_label\n",
    "        correct_pred = tf.equal(self.prediction, mask_label)\n",
    "        correct_index = tf.cast(correct_pred, tf.float32)\n",
    "        self.accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0818 11:22:52.214461 140542686246720 deprecation.py:506] From /home/husein/.local/lib/python3.6/site-packages/tensorflow/python/util/deprecation.py:507: calling count_nonzero (from tensorflow.python.ops.math_ops) with axis is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "reduction_indices is deprecated, use axis instead\n",
      "W0818 11:22:52.233758 140542686246720 deprecation.py:323] From <ipython-input-13-2e47c29a6de4>:50: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "W0818 11:22:52.237230 140542686246720 deprecation.py:323] From <ipython-input-13-2e47c29a6de4>:54: conv1d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.keras.layers.Conv1D` instead.\n",
      "W0818 11:22:52.241859 140542686246720 deprecation.py:506] From /home/husein/.local/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "W0818 11:22:52.619812 140542686246720 deprecation.py:323] From <ipython-input-13-2e47c29a6de4>:64: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.dense instead.\n",
      "W0818 11:22:52.893860 140542686246720 deprecation.py:323] From <ipython-input-13-2e47c29a6de4>:67: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.cast` instead.\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "sess = tf.InteractiveSession()\n",
    "\n",
    "size_layers = 256\n",
    "learning_rate = 1e-3\n",
    "num_layers = 3\n",
    "batch_size = 128\n",
    "epoch = 20\n",
    "\n",
    "model = Model(num_layers, size_layers, learning_rate, train_X[0].shape[1])\n",
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "minibatch loop: 100%|██████████| 64/64 [01:29<00:00,  1.45s/it, accuracy=0.141, cost=50.7]  \n",
      "testing minibatch loop: 100%|██████████| 3/3 [00:03<00:00,  1.21s/it, accuracy=0.136, cost=48.7]\n",
      "minibatch loop:   0%|          | 0/64 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1, training avg cost 66.266273, training avg accuracy 0.072635\n",
      "epoch 1, testing avg cost 51.142719, testing avg accuracy 0.129454\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "minibatch loop: 100%|██████████| 64/64 [01:46<00:00,  1.76s/it, accuracy=0.367, cost=36.7]\n",
      "testing minibatch loop: 100%|██████████| 3/3 [00:04<00:00,  1.38s/it, accuracy=0.37, cost=33.8] \n",
      "minibatch loop:   0%|          | 0/64 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 2, training avg cost 43.313988, training avg accuracy 0.262416\n",
      "epoch 2, testing avg cost 35.697575, testing avg accuracy 0.354671\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "minibatch loop: 100%|██████████| 64/64 [01:59<00:00,  1.87s/it, accuracy=0.447, cost=30.7]\n",
      "testing minibatch loop: 100%|██████████| 3/3 [00:04<00:00,  1.46s/it, accuracy=0.49, cost=28.4] \n",
      "minibatch loop:   0%|          | 0/64 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 3, training avg cost 34.173645, training avg accuracy 0.417441\n",
      "epoch 3, testing avg cost 30.267899, testing avg accuracy 0.471590\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "minibatch loop: 100%|██████████| 64/64 [02:04<00:00,  1.94s/it, accuracy=0.481, cost=27.8]\n",
      "testing minibatch loop: 100%|██████████| 3/3 [00:04<00:00,  1.49s/it, accuracy=0.556, cost=26.2]\n",
      "minibatch loop:   0%|          | 0/64 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 4, training avg cost 30.125032, training avg accuracy 0.467249\n",
      "epoch 4, testing avg cost 27.752932, testing avg accuracy 0.523138\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "minibatch loop: 100%|██████████| 64/64 [02:07<00:00,  1.97s/it, accuracy=0.522, cost=25.6]\n",
      "testing minibatch loop: 100%|██████████| 3/3 [00:04<00:00,  1.53s/it, accuracy=0.567, cost=25]  \n",
      "minibatch loop:   0%|          | 0/64 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 5, training avg cost 27.510384, training avg accuracy 0.503978\n",
      "epoch 5, testing avg cost 26.228933, testing avg accuracy 0.541760\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "minibatch loop: 100%|██████████| 64/64 [02:09<00:00,  2.01s/it, accuracy=0.548, cost=23.8]\n",
      "testing minibatch loop: 100%|██████████| 3/3 [00:04<00:00,  1.56s/it, accuracy=0.588, cost=23.8]\n",
      "minibatch loop:   0%|          | 0/64 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 6, training avg cost 25.448170, training avg accuracy 0.524070\n",
      "epoch 6, testing avg cost 24.915697, testing avg accuracy 0.560023\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "minibatch loop: 100%|██████████| 64/64 [02:10<00:00,  2.02s/it, accuracy=0.552, cost=22.4]\n",
      "testing minibatch loop: 100%|██████████| 3/3 [00:04<00:00,  1.58s/it, accuracy=0.589, cost=23.2]\n",
      "minibatch loop:   0%|          | 0/64 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 7, training avg cost 23.679810, training avg accuracy 0.536137\n",
      "epoch 7, testing avg cost 24.132856, testing avg accuracy 0.563886\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "minibatch loop: 100%|██████████| 64/64 [02:12<00:00,  2.05s/it, accuracy=0.564, cost=20.9]\n",
      "testing minibatch loop: 100%|██████████| 3/3 [00:04<00:00,  1.60s/it, accuracy=0.586, cost=22.5]\n",
      "minibatch loop:   0%|          | 0/64 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 8, training avg cost 22.059464, training avg accuracy 0.545352\n",
      "epoch 8, testing avg cost 23.355932, testing avg accuracy 0.564997\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "minibatch loop: 100%|██████████| 64/64 [02:13<00:00,  2.08s/it, accuracy=0.571, cost=19.6]\n",
      "testing minibatch loop: 100%|██████████| 3/3 [00:04<00:00,  1.62s/it, accuracy=0.589, cost=22.1]\n",
      "minibatch loop:   0%|          | 0/64 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 9, training avg cost 20.561428, training avg accuracy 0.552367\n",
      "epoch 9, testing avg cost 22.863043, testing avg accuracy 0.567885\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "minibatch loop: 100%|██████████| 64/64 [02:15<00:00,  2.10s/it, accuracy=0.577, cost=18.1]\n",
      "testing minibatch loop: 100%|██████████| 3/3 [00:04<00:00,  1.62s/it, accuracy=0.597, cost=21.6]\n",
      "minibatch loop:   0%|          | 0/64 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 10, training avg cost 19.124722, training avg accuracy 0.557998\n",
      "epoch 10, testing avg cost 22.348738, testing avg accuracy 0.575232\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "minibatch loop: 100%|██████████| 64/64 [02:16<00:00,  2.12s/it, accuracy=0.575, cost=16.8]\n",
      "testing minibatch loop: 100%|██████████| 3/3 [00:04<00:00,  1.67s/it, accuracy=0.6, cost=21.3]  \n",
      "minibatch loop:   0%|          | 0/64 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 11, training avg cost 17.750248, training avg accuracy 0.564327\n",
      "epoch 11, testing avg cost 22.032114, testing avg accuracy 0.578025\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "minibatch loop: 100%|██████████| 64/64 [02:16<00:00,  2.11s/it, accuracy=0.583, cost=15.6]\n",
      "testing minibatch loop: 100%|██████████| 3/3 [00:04<00:00,  1.67s/it, accuracy=0.601, cost=21.3]\n",
      "minibatch loop:   0%|          | 0/64 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 12, training avg cost 16.451698, training avg accuracy 0.570414\n",
      "epoch 12, testing avg cost 21.884588, testing avg accuracy 0.580322\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "minibatch loop: 100%|██████████| 64/64 [02:17<00:00,  2.12s/it, accuracy=0.587, cost=14.4]\n",
      "testing minibatch loop: 100%|██████████| 3/3 [00:04<00:00,  1.67s/it, accuracy=0.6, cost=21.3]  \n",
      "minibatch loop:   0%|          | 0/64 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 13, training avg cost 15.290417, training avg accuracy 0.575543\n",
      "epoch 13, testing avg cost 21.763412, testing avg accuracy 0.580609\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "minibatch loop: 100%|██████████| 64/64 [02:18<00:00,  2.16s/it, accuracy=0.594, cost=13.4]\n",
      "testing minibatch loop: 100%|██████████| 3/3 [00:04<00:00,  1.68s/it, accuracy=0.601, cost=21.6]\n",
      "minibatch loop:   0%|          | 0/64 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 14, training avg cost 14.264177, training avg accuracy 0.579963\n",
      "epoch 14, testing avg cost 21.796240, testing avg accuracy 0.584683\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "minibatch loop: 100%|██████████| 64/64 [02:18<00:00,  2.13s/it, accuracy=0.592, cost=12.4]\n",
      "testing minibatch loop: 100%|██████████| 3/3 [00:04<00:00,  1.67s/it, accuracy=0.595, cost=21.9]\n",
      "minibatch loop:   0%|          | 0/64 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 15, training avg cost 13.274798, training avg accuracy 0.585419\n",
      "epoch 15, testing avg cost 21.912636, testing avg accuracy 0.580520\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "minibatch loop: 100%|██████████| 64/64 [02:19<00:00,  2.15s/it, accuracy=0.597, cost=11.4]\n",
      "testing minibatch loop: 100%|██████████| 3/3 [00:04<00:00,  1.65s/it, accuracy=0.594, cost=21.9]\n",
      "minibatch loop:   0%|          | 0/64 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 16, training avg cost 12.349021, training avg accuracy 0.590741\n",
      "epoch 16, testing avg cost 22.235825, testing avg accuracy 0.576552\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "minibatch loop: 100%|██████████| 64/64 [02:20<00:00,  2.16s/it, accuracy=0.609, cost=10.5]\n",
      "testing minibatch loop: 100%|██████████| 3/3 [00:04<00:00,  1.67s/it, accuracy=0.599, cost=22.2]\n",
      "minibatch loop:   0%|          | 0/64 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 17, training avg cost 11.494472, training avg accuracy 0.594840\n",
      "epoch 17, testing avg cost 22.365992, testing avg accuracy 0.576959\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "minibatch loop: 100%|██████████| 64/64 [02:20<00:00,  2.16s/it, accuracy=0.618, cost=9.77]\n",
      "testing minibatch loop: 100%|██████████| 3/3 [00:04<00:00,  1.68s/it, accuracy=0.605, cost=22.3]\n",
      "minibatch loop:   0%|          | 0/64 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 18, training avg cost 10.745575, training avg accuracy 0.597572\n",
      "epoch 18, testing avg cost 22.457262, testing avg accuracy 0.585130\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "minibatch loop: 100%|██████████| 64/64 [02:20<00:00,  2.18s/it, accuracy=0.609, cost=9.69]\n",
      "testing minibatch loop: 100%|██████████| 3/3 [00:04<00:00,  1.68s/it, accuracy=0.604, cost=22.3]\n",
      "minibatch loop:   0%|          | 0/64 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 19, training avg cost 10.153742, training avg accuracy 0.601557\n",
      "epoch 19, testing avg cost 22.512693, testing avg accuracy 0.585935\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "minibatch loop: 100%|██████████| 64/64 [02:20<00:00,  2.16s/it, accuracy=0.638, cost=9.08]\n",
      "testing minibatch loop: 100%|██████████| 3/3 [00:05<00:00,  1.72s/it, accuracy=0.606, cost=22.8]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 20, training avg cost 9.581175, training avg accuracy 0.605466\n",
      "epoch 20, testing avg cost 22.805923, testing avg accuracy 0.593097\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for e in range(epoch):\n",
    "    pbar = tqdm(\n",
    "        range(0, len(train_X), batch_size), desc = 'minibatch loop')\n",
    "    train_cost, train_accuracy, test_cost, test_accuracy = [], [], [], []\n",
    "    for i in pbar:\n",
    "        batch_x = train_X[i : min(i + batch_size, len(train_X))]\n",
    "        y = train_Y[i : min(i + batch_size, len(train_X))]\n",
    "        batch_y = sparse_tuple_from(y)\n",
    "        batch_label, batch_len = pad_sentence_batch(y, 0)\n",
    "        _, cost, accuracy = sess.run(\n",
    "            [model.optimizer, model.cost, model.accuracy],\n",
    "            feed_dict = {model.X: batch_x, model.Y: batch_y, \n",
    "                         model.label: batch_label, model.Y_seq_len: batch_len},\n",
    "        )\n",
    "        train_cost.append(cost)\n",
    "        train_accuracy.append(accuracy)\n",
    "        pbar.set_postfix(cost = cost, accuracy = accuracy)\n",
    "    \n",
    "    pbar = tqdm(\n",
    "        range(0, len(test_X), batch_size), desc = 'testing minibatch loop')\n",
    "    for i in pbar:\n",
    "        batch_x = test_X[i : min(i + batch_size, len(test_X))]\n",
    "        y = test_Y[i : min(i + batch_size, len(test_X))]\n",
    "        batch_y = sparse_tuple_from(y)\n",
    "        batch_label, batch_len = pad_sentence_batch(y, 0)\n",
    "        cost, accuracy = sess.run(\n",
    "            [model.cost, model.accuracy],\n",
    "            feed_dict = {model.X: batch_x, model.Y: batch_y, \n",
    "                         model.label: batch_label, model.Y_seq_len: batch_len},\n",
    "        )\n",
    "        \n",
    "        test_cost.append(cost)\n",
    "        test_accuracy.append(accuracy)\n",
    "        \n",
    "        pbar.set_postfix(cost = cost, accuracy = accuracy)\n",
    "    \n",
    "    print('epoch %d, training avg cost %f, training avg accuracy %f'%(e + 1, np.mean(train_cost), \n",
    "                                                                      np.mean(train_accuracy)))\n",
    "    \n",
    "    print('epoch %d, testing avg cost %f, testing avg accuracy %f'%(e + 1, np.mean(test_cost), \n",
    "                                                                    np.mean(test_accuracy)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "real: sebut perkataan ambasador\n",
      "predicted: sebut perkatan ambaton\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "random_index = random.randint(0, len(test_X) - 1)\n",
    "batch_x = test_X[random_index : random_index + 1]\n",
    "print(\n",
    "    'real:',\n",
    "    ''.join(\n",
    "        [idx2char[no] for no in test_Y[random_index : random_index + 1][0]]\n",
    "    ),\n",
    ")\n",
    "batch_y = sparse_tuple_from(test_Y[random_index : random_index + 1])\n",
    "pred = sess.run(model.preds, feed_dict = {model.X: batch_x})[0]\n",
    "print('predicted:', ''.join([idx2char[no] for no in pred]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
